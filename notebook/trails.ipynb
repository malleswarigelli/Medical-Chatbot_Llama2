{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\anjik\\\\Desktop\\\\MLOPs_projects\\\\Gen_AI\\\\Medical-Chatbot_Llama2\\\\notebook'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\anjik\\\\Desktop\\\\MLOPs_projects\\\\Gen_AI\\\\Medical-Chatbot_Llama2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anjik\\anaconda3\\envs\\medibot\\lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA # chain for Q&A against an vector store index\n",
    "from langchain.embeddings import HuggingFaceEmbeddings # wrapper around sentense_transformers embedding models\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "import os\n",
    "\n",
    "# to load pdf files\n",
    "from langchain.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "\n",
    "# chunking\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PINECONE API KEY from .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pcsk_5J7nq2_sA7PCqEktiF4KxRt32Yo7FhxeB3Fx4QqpztFD6WKBos4ruF4wAmi5vPZjEVRBK'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "PINECONE_API_KEY=os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pdf file, extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data):\n",
    "    loader= DirectoryLoader(path=data, \n",
    "                               glob=\"*.pdf\", \n",
    "                               loader_cls=PyPDFLoader)\n",
    "    documents= loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\Medical_book.pdf', 'page': 0}, page_content=''),\n",
       " Document(metadata={'source': 'data\\\\Medical_book.pdf', 'page': 1}, page_content='The GALE\\nENCYCLOPEDIA\\nof MEDICINE\\nSECOND EDITION'),\n",
       " Document(metadata={'source': 'data\\\\Medical_book.pdf', 'page': 2}, page_content='The GALE\\nENCYCLOPEDIA\\nof MEDICINE\\nSECOND EDITION\\nJACQUELINE L. LONGE, EDITOR\\nDEIRDRE S. BLANCHFIELD, ASSOCIATE EDITOR\\nVOLUME\\nA-B\\n1'),\n",
       " Document(metadata={'source': 'data\\\\Medical_book.pdf', 'page': 3}, page_content='STAFF\\nJacqueline L. Longe, Project Editor\\nDeirdre S. Blanchfield, Associate Editor\\nChristine B. Jeryan, Managing Editor\\nDonna Olendorf, Senior Editor\\nStacey Blachford, Associate Editor\\nKate Kretschmann, Melissa C. McDade, Ryan\\nThomason, Assistant Editors\\nMark Springer, Technical Specialist\\nAndrea Lopeman, Programmer/Analyst\\nBarbara J. Yarrow,Manager, Imaging and Multimedia\\nContent\\nRobyn V . Young,Project Manager, Imaging and\\nMultimedia Content\\nDean Dauphinais, Senior Editor, Imaging and\\nMultimedia Content\\nKelly A. Quin, Editor, Imaging and Multimedia Content\\nLeitha Etheridge-Sims, Mary K. Grimes, Dave Oblender,\\nImage Catalogers\\nPamela A. Reed, Imaging Coordinator\\nRandy Bassett, Imaging Supervisor\\nRobert Duncan, Senior Imaging Specialist\\nDan Newell, Imaging Specialist\\nChristine O’Bryan,Graphic Specialist\\nMaria Franklin, Permissions Manager\\nMargaret A. Chamberlain, Permissions Specialist\\nMichelle DiMercurio, Senior Art Director\\nMike Logusz, Graphic Artist\\nMary Beth Trimper,Manager, Composition and\\nElectronic Prepress\\nEvi Seoud, Assistant Manager, Composition Purchasing\\nand Electronic Prepress\\nDorothy Maki, Manufacturing Manager\\nWendy Blurton, Senior Manufacturing Specialist\\nThe GALE\\nENCYCLOPEDIA\\nof MEDICINE\\nSECOND EDITION\\nSince this page cannot legibly accommodate all copyright notices, the\\nacknowledgments constitute an extension of the copyright notice.\\nWhile every effort has been made to ensure the reliability of the infor-\\nmation presented in this publication, the Gale Group neither guarantees\\nthe accuracy of the data contained herein nor assumes any responsibili-\\nty for errors, omissions or discrepancies. The Gale Group accepts no\\npayment for listing, and inclusion in the publication of any organiza-\\ntion, agency, institution, publication, service, or individual does not\\nimply endorsement of the editor or publisher. Errors brought to the\\nattention of the publisher and verified to the satisfaction of the publish-\\ner will be corrected in future editions.\\nThis book is printed on recycled paper that meets Environmental Pro-\\ntection Agency standards.\\nThe paper used in this publication meets the minimum requirements of\\nAmerican National Standard for Information Sciences-Permanence\\nPaper for Printed Library Materials, ANSI Z39.48-1984.\\nThis publication is a creative work fully protected by all applicable\\ncopyright laws, as well as by misappropriation, trade secret, unfair com-\\npetition, and other applicable laws. The authors and editor of this work\\nhave added value to the underlying factual material herein through one\\nor more of the following: unique and original selection, coordination,\\nexpression, arrangement, and classification of the information.\\nGale Group and design is a trademark used herein under license.\\nAll rights to this publication will be vigorously defended.\\nCopyright © 2002\\nGale Group\\n27500 Drake Road\\nFarmington Hills, MI 48331-3535\\nAll rights reserved including the right of reproduction in whole or in\\npart in any form.\\nISBN 0-7876-5489-2 (set)\\n0-7876-5490-6 (V ol. 1)\\n0-7876-5491-4 (V ol. 2)\\n0-7876-5492-2 (V ol. 3)\\n0-7876-5493-0 (V ol. 4)\\n0-7876-5494-9 (V ol. 5)\\nPrinted in the United States of America\\n10 9 8 7 6 5 4 3 2 1\\nLibrary of Congress Cataloging-in-Publication Data\\nGale encyclopedia of medicine / Jacqueline L. Longe, editor;\\nDeirdre S. Blanchfield, associate editor — 2nd ed.\\np. cm.\\nIncludes bibliographical references and index.\\nContents: V ol. 1. A-B — v. 2. C-F — v. 3.\\nG-M — v. 4. N-S — v. 5. T-Z.\\nISBN 0-7876-5489-2 (set: hardcover) — ISBN 0-7876-5490-6\\n(vol. 1) — ISBN 0-7876-5491-4 (vol. 2) — ISBN 0-7876-5492-2\\n(vol. 3) — ISBN 0-7876-5493-0 (vol. 4) — ISBN 0-7876-5494-9\\n(vol. 5)\\n1. Internal medicine—Encyclopedias. I. Longe, Jacqueline L. \\nII. Blanchfield, Deirdre S. III. Gale Research Company.\\nRC41.G35 2001\\n616’.003—dc21\\n2001051245'),\n",
       " Document(metadata={'source': 'data\\\\Medical_book.pdf', 'page': 4}, page_content='Introduction.................................................... ix\\nAdvisory Board.............................................. xi\\nContributors ................................................. xiii\\nEntries\\nVolume 1: A-B.............................................. 1\\nVolume 2: C-F.......................................... 625\\nVolume 3: G-M....................................... 1375\\nVolume 4: N-S........................................ 2307\\nVolume 5: T-Z........................................ 3237\\nOrganizations ............................................ 3603\\nGeneral Index............................................ 3625\\nGALE ENCYCLOPEDIA OF MEDICINE 2 V\\nCONTENTS')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents= load_data(\"data/\")\n",
    "documents[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_number: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"page_number:\", documents[0].metadata[\"page\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to make text chunks\n",
    "\n",
    "def text_split(documents):\n",
    "    text_splitter= RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks= text_splitter.split_documents(documents)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\Medical_book.pdf', 'page': 1}, page_content='The GALE\\nENCYCLOPEDIA\\nof MEDICINE\\nSECOND EDITION'),\n",
       " Document(metadata={'source': 'data\\\\Medical_book.pdf', 'page': 2}, page_content='The GALE\\nENCYCLOPEDIA\\nof MEDICINE\\nSECOND EDITION\\nJACQUELINE L. LONGE, EDITOR\\nDEIRDRE S. BLANCHFIELD, ASSOCIATE EDITOR\\nVOLUME\\nA-B\\n1'),\n",
       " Document(metadata={'source': 'data\\\\Medical_book.pdf', 'page': 3}, page_content='STAFF\\nJacqueline L. Longe, Project Editor\\nDeirdre S. Blanchfield, Associate Editor\\nChristine B. Jeryan, Managing Editor\\nDonna Olendorf, Senior Editor\\nStacey Blachford, Associate Editor\\nKate Kretschmann, Melissa C. McDade, Ryan\\nThomason, Assistant Editors\\nMark Springer, Technical Specialist\\nAndrea Lopeman, Programmer/Analyst\\nBarbara J. Yarrow,Manager, Imaging and Multimedia\\nContent\\nRobyn V . Young,Project Manager, Imaging and\\nMultimedia Content\\nDean Dauphinais, Senior Editor, Imaging and'),\n",
       " Document(metadata={'source': 'data\\\\Medical_book.pdf', 'page': 3}, page_content='Multimedia Content\\nKelly A. Quin, Editor, Imaging and Multimedia Content\\nLeitha Etheridge-Sims, Mary K. Grimes, Dave Oblender,\\nImage Catalogers\\nPamela A. Reed, Imaging Coordinator\\nRandy Bassett, Imaging Supervisor\\nRobert Duncan, Senior Imaging Specialist\\nDan Newell, Imaging Specialist\\nChristine O’Bryan,Graphic Specialist\\nMaria Franklin, Permissions Manager\\nMargaret A. Chamberlain, Permissions Specialist\\nMichelle DiMercurio, Senior Art Director\\nMike Logusz, Graphic Artist'),\n",
       " Document(metadata={'source': 'data\\\\Medical_book.pdf', 'page': 3}, page_content='Mary Beth Trimper,Manager, Composition and\\nElectronic Prepress\\nEvi Seoud, Assistant Manager, Composition Purchasing\\nand Electronic Prepress\\nDorothy Maki, Manufacturing Manager\\nWendy Blurton, Senior Manufacturing Specialist\\nThe GALE\\nENCYCLOPEDIA\\nof MEDICINE\\nSECOND EDITION\\nSince this page cannot legibly accommodate all copyright notices, the\\nacknowledgments constitute an extension of the copyright notice.\\nWhile every effort has been made to ensure the reliability of the infor-'),\n",
       " Document(metadata={'source': 'data\\\\Medical_book.pdf', 'page': 3}, page_content='mation presented in this publication, the Gale Group neither guarantees\\nthe accuracy of the data contained herein nor assumes any responsibili-\\nty for errors, omissions or discrepancies. The Gale Group accepts no\\npayment for listing, and inclusion in the publication of any organiza-\\ntion, agency, institution, publication, service, or individual does not\\nimply endorsement of the editor or publisher. Errors brought to the\\nattention of the publisher and verified to the satisfaction of the publish-'),\n",
       " Document(metadata={'source': 'data\\\\Medical_book.pdf', 'page': 3}, page_content='er will be corrected in future editions.\\nThis book is printed on recycled paper that meets Environmental Pro-\\ntection Agency standards.\\nThe paper used in this publication meets the minimum requirements of\\nAmerican National Standard for Information Sciences-Permanence\\nPaper for Printed Library Materials, ANSI Z39.48-1984.\\nThis publication is a creative work fully protected by all applicable\\ncopyright laws, as well as by misappropriation, trade secret, unfair com-'),\n",
       " Document(metadata={'source': 'data\\\\Medical_book.pdf', 'page': 3}, page_content='petition, and other applicable laws. The authors and editor of this work\\nhave added value to the underlying factual material herein through one\\nor more of the following: unique and original selection, coordination,\\nexpression, arrangement, and classification of the information.\\nGale Group and design is a trademark used herein under license.\\nAll rights to this publication will be vigorously defended.\\nCopyright © 2002\\nGale Group\\n27500 Drake Road\\nFarmington Hills, MI 48331-3535'),\n",
       " Document(metadata={'source': 'data\\\\Medical_book.pdf', 'page': 3}, page_content='All rights reserved including the right of reproduction in whole or in\\npart in any form.\\nISBN 0-7876-5489-2 (set)\\n0-7876-5490-6 (V ol. 1)\\n0-7876-5491-4 (V ol. 2)\\n0-7876-5492-2 (V ol. 3)\\n0-7876-5493-0 (V ol. 4)\\n0-7876-5494-9 (V ol. 5)\\nPrinted in the United States of America\\n10 9 8 7 6 5 4 3 2 1\\nLibrary of Congress Cataloging-in-Publication Data\\nGale encyclopedia of medicine / Jacqueline L. Longe, editor;\\nDeirdre S. Blanchfield, associate editor — 2nd ed.\\np. cm.'),\n",
       " Document(metadata={'source': 'data\\\\Medical_book.pdf', 'page': 3}, page_content='p. cm.\\nIncludes bibliographical references and index.\\nContents: V ol. 1. A-B — v. 2. C-F — v. 3.\\nG-M — v. 4. N-S — v. 5. T-Z.\\nISBN 0-7876-5489-2 (set: hardcover) — ISBN 0-7876-5490-6\\n(vol. 1) — ISBN 0-7876-5491-4 (vol. 2) — ISBN 0-7876-5492-2\\n(vol. 3) — ISBN 0-7876-5493-0 (vol. 4) — ISBN 0-7876-5494-9\\n(vol. 5)\\n1. Internal medicine—Encyclopedias. I. Longe, Jacqueline L. \\nII. Blanchfield, Deirdre S. III. Gale Research Company.\\nRC41.G35 2001\\n616’.003—dc21\\n2001051245')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks= text_split(documents)\n",
    "print(len(text_chunks))\n",
    "text_chunks[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store chunks in vector DB ---> before that convert chunks into vector representation i.e Embedding the data\n",
    "\n",
    "- using embedding model: \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "- It is a sentence transformers model, maps sentenses and paragraphs to a `384` dimensional dense vector --> used for clustering and/or semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download embedding model\n",
    "\n",
    "def download_huggingface_embedding_model():\n",
    "    embedding_model= HuggingFaceEmbeddings(model_name = \"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anjik\\AppData\\Local\\Temp\\ipykernel_3800\\1011557484.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model= HuggingFaceEmbeddings(model_name = \"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model= download_huggingface_embedding_model()\n",
    "embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\anjik\\anaconda3\\envs\\medibot\\lib\\site-packages (3.3.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\anjik\\anaconda3\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (4.46.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\anjik\\anaconda3\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (4.67.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\anjik\\anaconda3\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\anjik\\anaconda3\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\anjik\\anaconda3\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\anjik\\anaconda3\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (0.26.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\anjik\\anaconda3\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\anjik\\anaconda3\\envs\\medibot\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\anjik\\anaconda3\\envs\\medibot\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\anjik\\anaconda3\\envs\\medibot\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\anjik\\anaconda3\\envs\\medibot\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\anjik\\anaconda3\\envs\\medibot\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\anjik\\anaconda3\\envs\\medibot\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\anjik\\anaconda3\\envs\\medibot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\anjik\\anaconda3\\envs\\medibot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\anjik\\anaconda3\\envs\\medibot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\anjik\\anaconda3\\envs\\medibot\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\anjik\\anaconda3\\envs\\medibot\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\anjik\\anaconda3\\envs\\medibot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\anjik\\anaconda3\\envs\\medibot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\anjik\\anaconda3\\envs\\medibot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\anjik\\anaconda3\\envs\\medibot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\anjik\\anaconda3\\envs\\medibot\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\anjik\\anaconda3\\envs\\medibot\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\anjik\\anaconda3\\envs\\medibot\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anjik\\anaconda3\\envs\\medibot\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anjik\\anaconda3\\envs\\medibot\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anjik\\anaconda3\\envs\\medibot\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anjik\\anaconda3\\envs\\medibot\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of embeddings: 384\n"
     ]
    }
   ],
   "source": [
    "# embedding test\n",
    "query_result= embedding_model.embed_query(\"Hello world\")\n",
    "print(\"Length of embeddings:\", len(query_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize pinecone, create index, saves chunks and embeddings into index of pinecone DB \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "import os\n",
    "\n",
    "\n",
    "pinecone_obj = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "\n",
    "index_name = \"medical-chatbot-vector-index\"\n",
    "\n",
    "pinecone_obj.create_index(\n",
    "    name=index_name,\n",
    "    dimension=384, # Replace with your model dimensions\n",
    "    metric=\"cosine\", # Replace with your model metric\n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"\n",
    "    ) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'PineconeGRPC' has no attribute 'init'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mPinecone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m(api_key\u001b[38;5;241m=\u001b[39m PINECONE_API_KEY,\n\u001b[0;32m      2\u001b[0m               environment\u001b[38;5;241m=\u001b[39m PINECONE_API_ENV)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# your pinecone index name\u001b[39;00m\n\u001b[0;32m      4\u001b[0m index_name\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedical_chatbot\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'PineconeGRPC' has no attribute 'init'"
     ]
    }
   ],
   "source": [
    "Pinecone.init(api_key= PINECONE_API_KEY,\n",
    "              environment= PINECONE_API_ENV)\n",
    "# your pinecone index name\n",
    "index_name= \"medical_chatbot\"\n",
    "\n",
    "# create embeddings for each of teh text chunks, store\n",
    "docsearch= Pinecone.from_texts([t.page_content for t in text_chunks], embedding_model, index_name=index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Give query, get rank results from Pinecone knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load index from pinecone\n",
    "docsearch= Pinecone.from_existing_index(index_name, embedding)\n",
    "query= \"What are allergies?\"\n",
    "\n",
    "# get top 3 similarity searches\n",
    "docs= docsearch.similarity_search(query, k=3)\n",
    "print(\"Result\", docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Give rank results to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt= PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "chain_type_kwargs= {\"prompt\":prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load llama model\n",
    "llm= CTransformers(model=\"model/llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "                   model_type=\"llama\",\n",
    "                   config={\"max_new_tokens\":512,\n",
    "                           \"temperature\":0.8})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create Q&A Retrival: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa= RetrievalQA.from_chain_type(llm=llm, \n",
    "                                chain_type= \"stuff\",\n",
    "                                retriever= docsearch.as_retriever(search_kwargs= {'k':2}),\n",
    "                                return_source_documents=True,\n",
    "                                chain_type_kwargs=chain_type_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_input= input(f\"Input Prompt:\")\n",
    "    result= qa({\"query\": user_input})\n",
    "    print(\"Response:\", result[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medibot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
